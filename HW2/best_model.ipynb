{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDVwVcC2ofHK"
      },
      "source": [
        "## ML HW2 sample code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rV0FCmEOSz0"
      },
      "source": [
        "#### Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMsNXtVLopQ2"
      },
      "source": [
        "# references: https://clay-atlas.com/us/blog/2021/08/25/pytorch-en-early-stopping/\n",
        "# references: https://chih-sheng-huang821.medium.com/03-pytorch-dataaug-a712a7a7f55e\n",
        "\n",
        "import os\n",
        "import random\n",
        "import glob\n",
        "import csv\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from torch.optim import Adam\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfyxtZsqrw-_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b61de5c3-e839-4519-d240-9885c4f1fc55"
      },
      "source": [
        "!gdown 1drrS7gnyzUJPPiQcDWcHdIXqzjy2n3yZ\n",
        "!unzip 'HW2.zip'"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1drrS7gnyzUJPPiQcDWcHdIXqzjy2n3yZ\n",
            "To: /content/HW2.zip\n",
            "\r  0% 0.00/41.9M [00:00<?, ?B/s]\r 48% 19.9M/41.9M [00:00<00:00, 197MB/s]\r100% 41.9M/41.9M [00:00<00:00, 253MB/s]\n",
            "Archive:  HW2.zip\n",
            "replace data/test/7728.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbV9AEejOSz2"
      },
      "source": [
        "#### Set arguments and random seed"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6lZxggZRVc8",
        "outputId": "997cfa8e-acfc-473c-acc4-45dd4e646649"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Oct 26 14:22:27 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   61C    P0    30W /  70W |   1440MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9hIGGaiOSz2"
      },
      "source": [
        "TRA_PATH = 'data/train/'\n",
        "TST_PATH = 'data/test/'\n",
        "LABEL_PATH = 'data/train.csv'\n",
        "DEVICE_ID = 0\n",
        "SEED = 5566\n",
        "NUM_ECPOCH = 100\n",
        "\n",
        "torch.cuda.set_device(DEVICE_ID)\n",
        "use_gpu = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_gpu else \"cpu\")\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6fQ5BNqozM0"
      },
      "source": [
        "#### Process data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7-7syI4L9XE"
      },
      "source": [
        "def load_train_data(img_path, label_path, valid_ratio=0.12):\n",
        "    train_label = pd.read_csv(label_path)['label'].values.tolist()\n",
        "    train_image = [f'{img_path}/{i+10000}.jpg' for i in range(len(train_label)-1)]\n",
        "    \n",
        "    train_data = list(zip(train_image, train_label))\n",
        "    random.shuffle(train_data)\n",
        "    \n",
        "    split_len = int(len(train_data) * valid_ratio)\n",
        "    train_set = train_data[split_len:]\n",
        "    valid_set = train_data[:split_len]\n",
        "    \n",
        "    return train_set, valid_set\n",
        "\n",
        "def load_test_data(img_path):\n",
        "    test_set = [f'{img_path}/{i}.jpg' for i in range(7000, 10000)]\n",
        "    return test_set\n",
        "    \n",
        "def compute_statistics(dataset):\n",
        "    data = []\n",
        "    for (img_path, label) in dataset:\n",
        "        data.append(np.array(Image.open(img_path)))\n",
        "    data = np.array(data)\n",
        "    return data.mean(), data.std()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyGNv3zQOSz4"
      },
      "source": [
        "train_set, valid_set = load_train_data(TRA_PATH, LABEL_PATH)\n",
        "test_set = load_test_data(TST_PATH)\n",
        "transform1 = transforms.Compose([transforms.RandomHorizontalFlip(p=0.5)])\n",
        "transform2 = transforms.Compose([transforms.RandomRotation(10, center=(36,32)), transforms.CenterCrop(54), transforms.Resize((64,64)), transforms.RandomHorizontalFlip(p=0.5)])\n",
        "transform3 = transforms.Compose([transforms.RandomRotation(10, center=(28,32)), transforms.CenterCrop(54), transforms.Resize((64,64)), transforms.RandomHorizontalFlip(p=0.5)])\n",
        "transform4 = transforms.Compose([transforms.RandomRotation(10, center=(32,32)), transforms.RandomCrop((59,59)), transforms.Resize((64,64)), transforms.RandomHorizontalFlip(p=0.5)])\n",
        "transform5 = transforms.Compose([transforms.RandomRotation(10, center=(32,32)), transforms.RandomCrop((54,54)), transforms.Resize((64,64)), transforms.RandomHorizontalFlip(p=0.5)])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voXR5jPVPnxp"
      },
      "source": [
        "#### Customize dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyMfGXwgMWQV"
      },
      "source": [
        "class FaceExpressionDataset(Dataset):\n",
        "    def __init__(self, data, augment=None):\n",
        "        self.data = data\n",
        "        self.augment = augment\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def normalize(self, data):\n",
        "\n",
        "      picture = data[0]\n",
        "      a = torch.max(picture)\n",
        "      b = torch.min(picture)\n",
        "      if (a-b != 0):\n",
        "        data[0] = (picture - b) / (a - b)\n",
        "      else:\n",
        "        data[0] = picture - picture\n",
        "      return data\n",
        "\n",
        "      \n",
        "      picture = data[0]\n",
        "      a = torch.mean(picture)\n",
        "      b = torch.std(picture)\n",
        "      if (b != 0):\n",
        "        data[0] = (picture - a) / b\n",
        "      else:\n",
        "        data[0] = picture - picture\n",
        "      return data\n",
        "\n",
        "\n",
        "      data[0] = data[0] / 255\n",
        "      return data\n",
        "\n",
        "    \n",
        "    def read_img(self, idx):\n",
        "        img = Image.open(self.data[idx][0])\n",
        "        if not self.augment is None:\n",
        "            img = self.augment(img)\n",
        "        img = torch.from_numpy(np.array(img)).float()\n",
        "        img = img.unsqueeze(0).float()\n",
        "        img = self.normalize(img)\n",
        "        return img\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img = self.read_img(idx)\n",
        "        label = self.data[idx][1]\n",
        "        return img, label\n",
        "    \n",
        "class TestingDataset(Dataset):\n",
        "    def __init__(self, data, augment=None):\n",
        "        self.data = data\n",
        "        self.augment = augment\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def normalize(self, data):\n",
        "\n",
        "      picture = data[0]\n",
        "      a = torch.max(picture)\n",
        "      b = torch.min(picture)\n",
        "      if (a-b != 0):\n",
        "        data[0] = (picture - b) / (a - b)\n",
        "      else:\n",
        "        data[0] = picture - picture\n",
        "      return data\n",
        "\n",
        "      picture = data[0]\n",
        "      a = torch.mean(picture)\n",
        "      b = torch.std(picture)\n",
        "      if (b != 0):\n",
        "        data[0] = (picture - a) / b\n",
        "      else:\n",
        "        data[0] = picture - picture\n",
        "      return data\n",
        "\n",
        "      data[0] = data[0] / 255\n",
        "      return data\n",
        "    \n",
        "    def read_img(self, idx):\n",
        "        img = Image.open(self.data[idx])\n",
        "        if not self.augment is None:\n",
        "            img = self.augment(img)\n",
        "        img = torch.from_numpy(np.array(img)).float()\n",
        "        img = img.unsqueeze(0).float()\n",
        "        img = self.normalize(img)\n",
        "        return img, self.data[idx].split('/')[-1][:-4]\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        img, name = self.read_img(idx)\n",
        "        \n",
        "        return img, name"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dm6AqmFzOSz6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b6b74e4-2583-44d1-9048-2f68430f9ff4"
      },
      "source": [
        "train_dataset0 = FaceExpressionDataset(train_set, None)\n",
        "train_dataset1 = FaceExpressionDataset(train_set, transform1)\n",
        "train_dataset2 = FaceExpressionDataset(train_set, transform2)\n",
        "train_dataset3 = FaceExpressionDataset(train_set, transform3)\n",
        "train_dataset4 = FaceExpressionDataset(train_set, transform4)\n",
        "train_dataset5 = FaceExpressionDataset(train_set, transform5)\n",
        "train_dataset = torch.utils.data.ConcatDataset([train_dataset1, train_dataset2, train_dataset3, train_dataset4, train_dataset5])\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "print(len(train_dataset3))\n",
        "print(len(train_dataset))\n",
        "\n",
        "valid_dataset = FaceExpressionDataset(valid_set)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "test_dataset = TestingDataset(test_set)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)  \n",
        "\n",
        "print(len(train_dataset4.__getitem__(5)[0][0]), len(train_dataset4.__getitem__(5)[0][0][3]))\n",
        "print(len(train_dataset3.__getitem__(5)[0][0]), len(train_dataset3.__getitem__(5)[0][0][3]))\n",
        "print(train_dataset0.__getitem__(3)[0][0][0])\n",
        "print(train_dataset0.__getitem__(3)[0][0][0])\n",
        "print(train_dataset4.__getitem__(5)[0][0][32])\n",
        "print(train_dataset5.__getitem__(5)[0][0][32])\n",
        "print(train_dataset4.__getitem__(5)[0][0][63])\n",
        "print(train_dataset5.__getitem__(5)[0][0][63])\n",
        "print(test_dataset.__getitem__(1395)[0][0][32])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22780\n",
            "113900\n",
            "64 64\n",
            "64 64\n",
            "tensor([0.5000, 0.5714, 0.6270, 0.6151, 0.5714, 0.5595, 0.5913, 0.6230, 0.6190,\n",
            "        0.6230, 0.6230, 0.6349, 0.6746, 0.7183, 0.7262, 0.7063, 0.7302, 0.7341,\n",
            "        0.7817, 0.7897, 0.7421, 0.7381, 0.7857, 0.8016, 0.7937, 0.7381, 0.7698,\n",
            "        0.8333, 0.8016, 0.7579, 0.8175, 0.9008, 0.9008, 0.8452, 0.7857, 0.7579,\n",
            "        0.7421, 0.7381, 0.7619, 0.8016, 0.8294, 0.8095, 0.7778, 0.7698, 0.7460,\n",
            "        0.6587, 0.6310, 0.6944, 0.7341, 0.7698, 0.8175, 0.8254, 0.7500, 0.6310,\n",
            "        0.5437, 0.5159, 0.3730, 0.3492, 0.3968, 0.4405, 0.4484, 0.4960, 0.4841,\n",
            "        0.3611])\n",
            "tensor([0.5000, 0.5714, 0.6270, 0.6151, 0.5714, 0.5595, 0.5913, 0.6230, 0.6190,\n",
            "        0.6230, 0.6230, 0.6349, 0.6746, 0.7183, 0.7262, 0.7063, 0.7302, 0.7341,\n",
            "        0.7817, 0.7897, 0.7421, 0.7381, 0.7857, 0.8016, 0.7937, 0.7381, 0.7698,\n",
            "        0.8333, 0.8016, 0.7579, 0.8175, 0.9008, 0.9008, 0.8452, 0.7857, 0.7579,\n",
            "        0.7421, 0.7381, 0.7619, 0.8016, 0.8294, 0.8095, 0.7778, 0.7698, 0.7460,\n",
            "        0.6587, 0.6310, 0.6944, 0.7341, 0.7698, 0.8175, 0.8254, 0.7500, 0.6310,\n",
            "        0.5437, 0.5159, 0.3730, 0.3492, 0.3968, 0.4405, 0.4484, 0.4960, 0.4841,\n",
            "        0.3611])\n",
            "tensor([0.1412, 0.2196, 0.3333, 0.4510, 0.5686, 0.6588, 0.7176, 0.7608, 0.7961,\n",
            "        0.8039, 0.8118, 0.8353, 0.8588, 0.8706, 0.8863, 0.8784, 0.8863, 0.8549,\n",
            "        0.8471, 0.8275, 0.7725, 0.6941, 0.6000, 0.5020, 0.3294, 0.3922, 0.6196,\n",
            "        0.7373, 0.7922, 0.8392, 0.8627, 0.8588, 0.8471, 0.8314, 0.8235, 0.8118,\n",
            "        0.8039, 0.8000, 0.8275, 0.8353, 0.8392, 0.8431, 0.8392, 0.8353, 0.8510,\n",
            "        0.8824, 0.9059, 0.8824, 0.8588, 0.8745, 0.8667, 0.8627, 0.8627, 0.6471,\n",
            "        0.4157, 0.1647, 0.0275, 0.0039, 0.0039, 0.0039, 0.0118, 0.1059, 0.5529,\n",
            "        0.9020])\n",
            "tensor([0.0157, 0.0039, 0.0549, 0.1176, 0.2196, 0.4000, 0.6000, 0.8235, 0.8667,\n",
            "        0.8667, 0.8784, 0.8863, 0.8667, 0.8941, 0.8941, 0.8980, 0.8980, 0.8902,\n",
            "        0.8745, 0.8667, 0.8706, 0.8627, 0.8510, 0.8392, 0.8314, 0.8353, 0.8275,\n",
            "        0.8235, 0.8314, 0.8431, 0.8588, 0.8667, 0.8471, 0.8157, 0.7647, 0.6745,\n",
            "        0.5255, 0.3569, 0.3255, 0.4588, 0.5529, 0.6392, 0.7216, 0.7961, 0.8549,\n",
            "        0.8275, 0.8627, 0.8784, 0.8902, 0.8941, 0.8784, 0.8627, 0.8392, 0.8157,\n",
            "        0.8078, 0.8000, 0.7843, 0.7451, 0.6980, 0.6314, 0.5333, 0.4196, 0.3098,\n",
            "        0.2235])\n",
            "tensor([0.9255, 0.9490, 0.9922, 0.9765, 0.5804, 0.2745, 0.2980, 0.5137, 0.6627,\n",
            "        0.5686, 0.4235, 0.2706, 0.2275, 0.2941, 0.3176, 0.2941, 0.2745, 0.2980,\n",
            "        0.3451, 0.4196, 0.5216, 0.6118, 0.6667, 0.6902, 0.7137, 0.7412, 0.7765,\n",
            "        0.7922, 0.7961, 0.7843, 0.7725, 0.7882, 0.8118, 0.8275, 0.8314, 0.8314,\n",
            "        0.8353, 0.8314, 0.8157, 0.7961, 0.7843, 0.7922, 0.8078, 0.8157, 0.7961,\n",
            "        0.7373, 0.6392, 0.4980, 0.3373, 0.2039, 0.1451, 0.1529, 0.4275, 0.3843,\n",
            "        0.2510, 0.1294, 0.0784, 0.0980, 0.1922, 0.3451, 0.4235, 0.3373, 0.3882,\n",
            "        0.4157])\n",
            "tensor([0.0000, 0.7098, 0.9176, 0.7412, 0.3765, 0.0157, 0.0745, 0.0196, 0.0235,\n",
            "        0.0745, 0.1647, 0.2588, 0.2863, 0.3176, 0.2941, 0.2510, 0.2588, 0.3216,\n",
            "        0.3961, 0.4235, 0.1961, 0.1216, 0.3020, 0.6314, 0.8745, 0.8431, 0.8235,\n",
            "        0.8706, 0.8510, 0.8275, 0.8431, 0.8275, 0.8118, 0.8275, 0.8471, 0.8588,\n",
            "        0.8431, 0.8078, 0.7725, 0.7490, 0.7412, 0.7451, 0.7412, 0.7255, 0.6824,\n",
            "        0.6196, 0.6510, 0.6745, 0.6824, 0.6902, 0.7176, 0.7333, 0.7255, 0.7098,\n",
            "        0.7020, 0.6902, 0.6745, 0.6549, 0.5765, 0.4784, 0.3647, 0.2784, 0.2275,\n",
            "        0.2118])\n",
            "tensor([0.7922, 1.0000, 0.8471, 0.3529, 0.0000, 0.0392, 0.0667, 0.0824, 0.1137,\n",
            "        0.0157, 0.0078, 0.1098, 0.4314, 0.5216, 0.5333, 0.4745, 0.5137, 0.5137,\n",
            "        0.4902, 0.4353, 0.3882, 0.3804, 0.4196, 0.4627, 0.4784, 0.3216, 0.1686,\n",
            "        0.1373, 0.2157, 0.3608, 0.5216, 0.6431, 0.5451, 0.5804, 0.6196, 0.6784,\n",
            "        0.7608, 0.8235, 0.8039, 0.7451, 0.8000, 0.8588, 0.6941, 0.3922, 0.2353,\n",
            "        0.6667, 0.9490, 0.9020, 0.8510, 0.5725, 0.4863, 0.7333, 0.9451, 0.8902,\n",
            "        0.7569, 0.7059, 0.8510, 0.9490, 0.8745, 0.7686, 0.8196, 0.8353, 0.7882,\n",
            "        0.8039])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLA_KBidRF73"
      },
      "source": [
        "#### Define module class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QwewjIWP39y"
      },
      "source": [
        "class FaceExpressionNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FaceExpressionNet, self).__init__()\n",
        "        # TODO\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(16, eps=1e-05, affine=True),\n",
        "            nn.LeakyReLU(negative_slope=0.05),\n",
        "            nn.MaxPool2d((2, 2)),\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=1), \n",
        "            nn.BatchNorm2d(32, eps=1e-05, affine=True),\n",
        "            nn.LeakyReLU(negative_slope=0.05),\n",
        "            nn.MaxPool2d((2, 2)), \n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1), \n",
        "            nn.BatchNorm2d(64, eps=1e-05, affine=True),\n",
        "            nn.LeakyReLU(negative_slope=0.05),\n",
        "            nn.MaxPool2d((2, 2)), \n",
        "            nn.Conv2d(64, 32, kernel_size=3, padding=1), \n",
        "            nn.BatchNorm2d(32, eps=1e-05, affine=True),\n",
        "            nn.LeakyReLU(negative_slope=0.05),\n",
        "            nn.MaxPool2d((2, 2)), \n",
        "            nn.Conv2d(32, 16, kernel_size=3, padding=1), \n",
        "            nn.BatchNorm2d(16, eps=1e-05, affine=True),\n",
        "            nn.LeakyReLU(negative_slope=0.05),\n",
        "            nn.MaxPool2d((2, 2)), \n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(16*2*2, 7),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        #image size (64,64)\n",
        "        x = self.conv(x) #(32,32)\n",
        "        x = x.flatten(start_dim=1)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyyjQS2eOSz7"
      },
      "source": [
        "#### Define training and testing process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFCMvUe0OSz7"
      },
      "source": [
        "def train(train_loader, model, loss_fn, use_gpu=True):\n",
        "    model.train()\n",
        "    train_loss = []\n",
        "    train_acc = []\n",
        "    # print(len(train_loader))\n",
        "    temp = 0\n",
        "    for (img, label) in train_loader:\n",
        "        # print(temp)\n",
        "        temp += 1\n",
        "        if use_gpu:\n",
        "            img = img.to(device)\n",
        "            label = label.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(img)\n",
        "        loss = loss_fn(output, label)\n",
        "        loss.backward()            \n",
        "        optimizer.step()\n",
        "        with torch.no_grad():\n",
        "            predict = torch.argmax(output, dim=-1)\n",
        "            acc = np.mean((label == predict).cpu().numpy())\n",
        "            train_acc.append(acc)\n",
        "            train_loss.append(loss.item())\n",
        "    print(\"Epoch: {}, train Loss: {:.4f}, train Acc: {:.4f}\".format(epoch + 1, np.mean(train_loss), np.mean(train_acc)))\n",
        "    return (np.mean(train_loss), np.mean(train_acc))\n",
        "    \n",
        "def valid(valid_loader, model, loss_fn, use_gpu=True):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        valid_loss = []\n",
        "        valid_acc = []\n",
        "        for idx, (img, label) in enumerate(valid_loader):\n",
        "            if use_gpu:\n",
        "                img = img.to(device)\n",
        "                label = label.to(device)\n",
        "            output = model(img)\n",
        "            loss = loss_fn(output, label)\n",
        "            predict = torch.argmax(output, dim=-1)\n",
        "            acc = (label == predict).cpu().tolist()\n",
        "            valid_loss.append(loss.item())\n",
        "            valid_acc += acc\n",
        "       \n",
        "        valid_acc = np.mean(valid_acc)\n",
        "        valid_loss = np.mean(valid_loss)\n",
        "        print(\"Epoch: {}, valid Loss: {:.4f}, valid Acc: {:.4f}\".format(epoch + 1, valid_loss, valid_acc))\n",
        "    return (valid_loss, valid_acc)\n",
        "\n",
        "def save_checkpoint(valid_acc, acc_record, epoch, prefix='model'):\n",
        "    # you can define the condition to save model :)\n",
        "    if valid_acc >= np.mean(acc_record[-5:]):    \n",
        "        checkpoint_path = f'{prefix}.pth'\n",
        "        torch.save(model.state_dict(), checkpoint_path)\n",
        "        print('model saved to %s' % checkpoint_path)\n",
        "\n",
        "def better(acc_record, los_record):\n",
        "    if max(acc_record) == acc_record[-1]: return 1\n",
        "    if min(los_record) == los_record[-1]: return 2\n",
        "    if (los_record[-1] < los_record[-2]): return 2\n",
        "    return 0"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBHN_XSsTF6p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e73ed4b8-0bc6-403d-d5b5-ec36944ccf49"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    model = FaceExpressionNet()\n",
        "    if use_gpu:\n",
        "        model.to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    \n",
        "    train_acc_record = []\n",
        "    train_los_record = []\n",
        "    valid_acc_record = []\n",
        "    valid_los_record = []\n",
        "    stop = 10\n",
        "\n",
        "    for epoch in range(NUM_ECPOCH):\n",
        "        torch.save(model.state_dict(), F\"newmodel.pth\" )\n",
        "        (train_loss, train_acc) = train(train_loader, model, loss_fn, use_gpu)\n",
        "        (valid_loss, valid_acc) = valid(valid_loader, model, loss_fn, use_gpu=True)\n",
        "        train_acc_record.append(train_acc)\n",
        "        train_los_record.append(train_loss)\n",
        "        valid_acc_record.append(valid_acc)\n",
        "        valid_los_record.append(valid_loss)\n",
        "        \n",
        "        temp = better(valid_acc_record, valid_los_record)\n",
        "        stop -= 1\n",
        "        if (temp == 1):\n",
        "            save_checkpoint(valid_acc, valid_acc_record, epoch, prefix='model')\n",
        "            stop = min(10, stop+5)\n",
        "        if (temp == 2):\n",
        "            stop = min(10, stop+2)\n",
        "        if (stop == 0):\n",
        "            break\n",
        "        \n",
        "        print('########################################################')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, train Loss: 1.3443, train Acc: 0.4848\n",
            "Epoch: 1, valid Loss: 1.2307, valid Acc: 0.5296\n",
            "model saved to model.pth\n",
            "########################################################\n",
            "Epoch: 2, train Loss: 1.1509, train Acc: 0.5641\n",
            "Epoch: 2, valid Loss: 1.1321, valid Acc: 0.5666\n",
            "model saved to model.pth\n",
            "########################################################\n",
            "Epoch: 3, train Loss: 1.0915, train Acc: 0.5838\n",
            "Epoch: 3, valid Loss: 1.1240, valid Acc: 0.5644\n",
            "########################################################\n",
            "Epoch: 4, train Loss: 1.0511, train Acc: 0.6012\n",
            "Epoch: 4, valid Loss: 1.0830, valid Acc: 0.5850\n",
            "model saved to model.pth\n",
            "########################################################\n",
            "Epoch: 5, train Loss: 1.0241, train Acc: 0.6113\n",
            "Epoch: 5, valid Loss: 1.0694, valid Acc: 0.6056\n",
            "model saved to model.pth\n",
            "########################################################\n",
            "Epoch: 6, train Loss: 1.0014, train Acc: 0.6191\n",
            "Epoch: 6, valid Loss: 1.0797, valid Acc: 0.5988\n",
            "########################################################\n",
            "Epoch: 7, train Loss: 0.9842, train Acc: 0.6279\n",
            "Epoch: 7, valid Loss: 1.0577, valid Acc: 0.6079\n",
            "model saved to model.pth\n",
            "########################################################\n",
            "Epoch: 8, train Loss: 0.9673, train Acc: 0.6338\n",
            "Epoch: 8, valid Loss: 1.0542, valid Acc: 0.6120\n",
            "model saved to model.pth\n",
            "########################################################\n",
            "Epoch: 9, train Loss: 0.9511, train Acc: 0.6386\n",
            "Epoch: 9, valid Loss: 1.0849, valid Acc: 0.6062\n",
            "########################################################\n",
            "Epoch: 10, train Loss: 0.9404, train Acc: 0.6458\n",
            "Epoch: 10, valid Loss: 1.0876, valid Acc: 0.6075\n",
            "########################################################\n",
            "Epoch: 11, train Loss: 0.9301, train Acc: 0.6503\n",
            "Epoch: 11, valid Loss: 1.0566, valid Acc: 0.6140\n",
            "model saved to model.pth\n",
            "########################################################\n",
            "Epoch: 12, train Loss: 0.9211, train Acc: 0.6518\n",
            "Epoch: 12, valid Loss: 1.0882, valid Acc: 0.6017\n",
            "########################################################\n",
            "Epoch: 13, train Loss: 0.9155, train Acc: 0.6544\n",
            "Epoch: 13, valid Loss: 1.0606, valid Acc: 0.6182\n",
            "model saved to model.pth\n",
            "########################################################\n",
            "Epoch: 14, train Loss: 0.9040, train Acc: 0.6594\n",
            "Epoch: 14, valid Loss: 1.0781, valid Acc: 0.6030\n",
            "########################################################\n",
            "Epoch: 15, train Loss: 0.8977, train Acc: 0.6614\n",
            "Epoch: 15, valid Loss: 1.0606, valid Acc: 0.6108\n",
            "########################################################\n",
            "Epoch: 16, train Loss: 0.8915, train Acc: 0.6638\n",
            "Epoch: 16, valid Loss: 1.0656, valid Acc: 0.6095\n",
            "########################################################\n",
            "Epoch: 17, train Loss: 0.8857, train Acc: 0.6648\n",
            "Epoch: 17, valid Loss: 1.0778, valid Acc: 0.6040\n",
            "########################################################\n",
            "Epoch: 18, train Loss: 0.8786, train Acc: 0.6700\n",
            "Epoch: 18, valid Loss: 1.0936, valid Acc: 0.5985\n",
            "########################################################\n",
            "Epoch: 19, train Loss: 0.8729, train Acc: 0.6710\n",
            "Epoch: 19, valid Loss: 1.0596, valid Acc: 0.6130\n",
            "########################################################\n",
            "Epoch: 20, train Loss: 0.8681, train Acc: 0.6722\n",
            "Epoch: 20, valid Loss: 1.0822, valid Acc: 0.6162\n",
            "########################################################\n",
            "Epoch: 21, train Loss: 0.8639, train Acc: 0.6753\n",
            "Epoch: 21, valid Loss: 1.0494, valid Acc: 0.6091\n",
            "########################################################\n",
            "Epoch: 22, train Loss: 0.8618, train Acc: 0.6749\n",
            "Epoch: 22, valid Loss: 1.0500, valid Acc: 0.6133\n",
            "########################################################\n",
            "Epoch: 23, train Loss: 0.8571, train Acc: 0.6781\n",
            "Epoch: 23, valid Loss: 1.0728, valid Acc: 0.6091\n",
            "########################################################\n",
            "Epoch: 24, train Loss: 0.8505, train Acc: 0.6794\n",
            "Epoch: 24, valid Loss: 1.0822, valid Acc: 0.6130\n",
            "########################################################\n",
            "Epoch: 25, train Loss: 0.8503, train Acc: 0.6795\n",
            "Epoch: 25, valid Loss: 1.0713, valid Acc: 0.6101\n",
            "########################################################\n",
            "Epoch: 26, train Loss: 0.8421, train Acc: 0.6827\n",
            "Epoch: 26, valid Loss: 1.1198, valid Acc: 0.6095\n",
            "########################################################\n",
            "Epoch: 27, train Loss: 0.8373, train Acc: 0.6833\n",
            "Epoch: 27, valid Loss: 1.0933, valid Acc: 0.6130\n",
            "########################################################\n",
            "Epoch: 28, train Loss: 0.8363, train Acc: 0.6850\n",
            "Epoch: 28, valid Loss: 1.0725, valid Acc: 0.6153\n",
            "########################################################\n",
            "Epoch: 29, train Loss: 0.8338, train Acc: 0.6864\n",
            "Epoch: 29, valid Loss: 1.0834, valid Acc: 0.6111\n",
            "########################################################\n",
            "Epoch: 30, train Loss: 0.8308, train Acc: 0.6867\n",
            "Epoch: 30, valid Loss: 1.0722, valid Acc: 0.6050\n",
            "########################################################\n",
            "Epoch: 31, train Loss: 0.8264, train Acc: 0.6886\n",
            "Epoch: 31, valid Loss: 1.0729, valid Acc: 0.6117\n",
            "########################################################\n",
            "Epoch: 32, train Loss: 0.8256, train Acc: 0.6889\n",
            "Epoch: 32, valid Loss: 1.0583, valid Acc: 0.6291\n",
            "model saved to model.pth\n",
            "########################################################\n",
            "Epoch: 33, train Loss: 0.8196, train Acc: 0.6911\n",
            "Epoch: 33, valid Loss: 1.0715, valid Acc: 0.6175\n",
            "########################################################\n",
            "Epoch: 34, train Loss: 0.8172, train Acc: 0.6925\n",
            "Epoch: 34, valid Loss: 1.0849, valid Acc: 0.6082\n",
            "########################################################\n",
            "Epoch: 35, train Loss: 0.8177, train Acc: 0.6913\n",
            "Epoch: 35, valid Loss: 1.0665, valid Acc: 0.6220\n",
            "########################################################\n",
            "Epoch: 36, train Loss: 0.8130, train Acc: 0.6941\n",
            "Epoch: 36, valid Loss: 1.0843, valid Acc: 0.6230\n",
            "########################################################\n",
            "Epoch: 37, train Loss: 0.8139, train Acc: 0.6938\n",
            "Epoch: 37, valid Loss: 1.1261, valid Acc: 0.6050\n",
            "########################################################\n",
            "Epoch: 38, train Loss: 0.8104, train Acc: 0.6943\n",
            "Epoch: 38, valid Loss: 1.1617, valid Acc: 0.5876\n",
            "########################################################\n",
            "Epoch: 39, train Loss: 0.8081, train Acc: 0.6946\n",
            "Epoch: 39, valid Loss: 1.0838, valid Acc: 0.6104\n",
            "########################################################\n",
            "Epoch: 40, train Loss: 0.8046, train Acc: 0.6976\n",
            "Epoch: 40, valid Loss: 1.0840, valid Acc: 0.6182\n",
            "########################################################\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-8e6ba3b48fd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_ECPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mF\"newmodel.pth\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mtrain_acc_record\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-a68021cca567>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, loss_fn, use_gpu)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mtrain_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkGMf63mdJ3Y",
        "outputId": "d27db115-c11f-4829-bbd7-f266927c61ec"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "1ru4DTNseQKt",
        "outputId": "ffb7c46e-6190-491f-d5c1-466138cf9546"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-1756a0f25384>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mF\"https://drive.google.com/file/d/1miwBgt4SoCNjMeg-kHJEdAmgsvRbIe5q/view?usp=sharing\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'https://drive.google.com/file/d/1miwBgt4SoCNjMeg-kHJEdAmgsvRbIe5q/view?usp=sharing'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def confusion_matrix(valid_loader, model):\n",
        "    model.eval()\n",
        "    matrix = [[0 for j in range (7)] for i in range (7)]\n",
        "    with torch.no_grad():\n",
        "        for idx, (img, label) in enumerate(valid_loader):\n",
        "            if use_gpu:\n",
        "                img = img.to(device)\n",
        "                label = label.to(device)\n",
        "            output = model(img)\n",
        "            predict = torch.argmax(output, dim=-1)\n",
        "            for i in range (len(label)):\n",
        "                matrix[label[i]][predict[i]] += 1\n",
        "    print(matrix)\n",
        "    for i in range (7):\n",
        "        sum = 0\n",
        "        for j in range (7):\n",
        "            sum += matrix[i][j]\n",
        "        if (sum == 0):\n",
        "            continue\n",
        "        for j in range (7):\n",
        "            matrix[i][j] /= sum\n",
        "    return matrix\n",
        "\n",
        "\n",
        "print(train_acc_record)\n",
        "print(train_los_record)\n",
        "print(valid_acc_record)\n",
        "print(valid_los_record)\n",
        "del model\n",
        "model = FaceExpressionNet()\n",
        "model.load_state_dict(torch.load('model.pth'))\n",
        "model = model.cuda()\n",
        "print(confusion_matrix(valid_loader, model))\n",
        "print(confusion_matrix(train_loader, model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVvhqq4A7Qil",
        "outputId": "c610df8b-c1cb-46f3-a226-7b4b674bd124"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.48479504785684563, 0.564099237931752, 0.5837673611111112, 0.6011847170203912, 0.61130520443196, 0.6191102267998335, 0.627922778818144, 0.6338249063670413, 0.6385689762796505, 0.6458268310445276, 0.6502971545984186, 0.6518024344569289, 0.654443989284228, 0.6593554931335831, 0.6614206200582605, 0.6637965563878485, 0.6648021353516438, 0.6699675535788598, 0.670965004681648, 0.672244980233042, 0.6752662687265919, 0.674918396275489, 0.6780586766541822, 0.6793926212026634, 0.6794638212650852, 0.6826896067415731, 0.683292694028298, 0.685019376820641, 0.6864385013524761, 0.6866810367249272, 0.6885715771951727, 0.6889331044527673, 0.6911289273824387, 0.6924931075738661, 0.6913174937578027, 0.6940881190178942, 0.6938192493757803, 0.6942874141697878, 0.6945627861007073, 0.6976286152725759]\n",
            "[1.3442871617467216, 1.1508865050385508, 1.091546395856343, 1.0510549551985238, 1.0240958590186044, 1.0013539865445555, 0.9841534210055062, 0.9673397722538938, 0.9511312628060244, 0.9403897618309836, 0.9300539725282219, 0.9211134187291178, 0.915530865312962, 0.9039964620986681, 0.8976752178052838, 0.8915456080034877, 0.8857134492879504, 0.878608226106408, 0.8729439302776637, 0.8681100412700953, 0.8638701826668858, 0.8618199602271733, 0.8570916700898932, 0.8504790419942877, 0.8503421577175012, 0.8420875335007572, 0.8373335151190169, 0.8363308978884407, 0.8338465267352844, 0.8307546098580522, 0.8264443173167411, 0.8255520887589187, 0.8196441812461681, 0.8171777671642517, 0.8176753960968404, 0.8129667560705978, 0.8138746141717675, 0.8103731178165822, 0.8080732442020031, 0.8046264851361178]\n",
            "[0.5296200901481004, 0.5666452028332261, 0.5643915003219575, 0.5849967804249839, 0.6056020605280104, 0.5988409529942048, 0.6078557630392788, 0.6120412105602061, 0.6062459755312298, 0.607533805537669, 0.6139729555698648, 0.6017385705086928, 0.6181584030907921, 0.603026400515132, 0.6107533805537669, 0.6094655505473278, 0.6039922730199614, 0.598518995492595, 0.6130070830650354, 0.6162266580811333, 0.609143593045718, 0.6133290405666452, 0.609143593045718, 0.6130070830650354, 0.6101094655505473, 0.6094655505473278, 0.6130070830650354, 0.6152607855763039, 0.6110753380553767, 0.6049581455247908, 0.6117192530585963, 0.6291049581455248, 0.6175144880875725, 0.6081777205408886, 0.6220218931101095, 0.6229877656149388, 0.6049581455247908, 0.5875724404378622, 0.6104314230521571, 0.6181584030907921]\n",
            "[1.230692572593689, 1.132106490135193, 1.1239993166923523, 1.0830144572257996, 1.0693966913223267, 1.079659068584442, 1.057748363018036, 1.0542206716537477, 1.0849161410331727, 1.0876346945762634, 1.0565969562530517, 1.0881890439987183, 1.0606029868125915, 1.0780918073654175, 1.0605601382255554, 1.0655950951576232, 1.0778224110603332, 1.093612678050995, 1.0595688104629517, 1.0821831321716309, 1.0493786931037903, 1.0499563384056092, 1.0728392577171326, 1.0822365188598633, 1.0713240909576416, 1.119835503101349, 1.0933089399337768, 1.0725038695335387, 1.0833635544776916, 1.0722422623634338, 1.0729291796684266, 1.058277006149292, 1.0714900922775268, 1.0848936200141908, 1.0664778470993042, 1.0842770171165466, 1.1261256504058839, 1.1616718435287476, 1.0837805771827698, 1.0840121078491212]\n",
            "[[241, 4, 33, 24, 74, 11, 53], [19, 16, 1, 4, 4, 0, 0], [50, 2, 165, 35, 101, 40, 47], [16, 1, 9, 657, 21, 15, 44], [60, 2, 61, 32, 282, 5, 94], [16, 3, 32, 15, 14, 260, 16], [27, 0, 16, 51, 91, 9, 333]]\n",
            "[[0.5477272727272727, 0.00909090909090909, 0.075, 0.05454545454545454, 0.16818181818181818, 0.025, 0.12045454545454545], [0.4318181818181818, 0.36363636363636365, 0.022727272727272728, 0.09090909090909091, 0.09090909090909091, 0.0, 0.0], [0.11363636363636363, 0.004545454545454545, 0.375, 0.07954545454545454, 0.22954545454545455, 0.09090909090909091, 0.10681818181818181], [0.020969855832241154, 0.001310615989515072, 0.011795543905635648, 0.8610747051114024, 0.027522935779816515, 0.019659239842726082, 0.057667103538663174], [0.11194029850746269, 0.0037313432835820895, 0.11380597014925373, 0.05970149253731343, 0.5261194029850746, 0.009328358208955223, 0.17537313432835822], [0.0449438202247191, 0.008426966292134831, 0.0898876404494382, 0.042134831460674156, 0.03932584269662921, 0.7303370786516854, 0.0449438202247191], [0.051233396584440226, 0.0, 0.030360531309297913, 0.0967741935483871, 0.17267552182163187, 0.017077798861480076, 0.6318785578747628]]\n",
            "[[9452, 151, 1211, 898, 2141, 249, 1593], [364, 1005, 143, 39, 167, 24, 48], [1747, 84, 7648, 878, 3396, 1303, 1424], [360, 22, 297, 26320, 512, 334, 965], [1470, 69, 1745, 1070, 11641, 132, 2798], [304, 24, 1037, 780, 276, 9673, 481], [903, 21, 749, 1851, 2632, 156, 13313]]\n",
            "[[0.6022300095571839, 0.009620898375278752, 0.07715833067856005, 0.057215673781459066, 0.13641287034087288, 0.015864925135393438, 0.10149729213125198], [0.20335195530726258, 0.5614525139664804, 0.07988826815642458, 0.021787709497206705, 0.09329608938547486, 0.013407821229050279, 0.026815642458100558], [0.10600728155339806, 0.005097087378640777, 0.4640776699029126, 0.05327669902912621, 0.20606796116504855, 0.07906553398058253, 0.08640776699029126], [0.012495661228740022, 0.0007636237417563346, 0.010308920513710518, 0.9135716765012148, 0.017771607080874698, 0.011593196806664353, 0.033495314127039225], [0.07767503302509908, 0.003645970937912814, 0.09220607661822985, 0.05653896961690885, 0.615112285336856, 0.0069749009247027744, 0.1478467635402906], [0.024174950298210734, 0.0019085487077534792, 0.08246520874751491, 0.062027833001988074, 0.02194831013916501, 0.7692246520874751, 0.03825049701789265], [0.04601273885350318, 0.0010700636942675159, 0.0381656050955414, 0.09431847133757962, 0.13411464968152867, 0.007949044585987261, 0.6783694267515924]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqMcl44nOSz9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "4b215e06-09d0-4871-a278-3c5dbaf39e3b"
      },
      "source": [
        "def test(test_loader, model, file_name='predict.csv'):\n",
        "    with torch.no_grad():\n",
        "        predict_result = []\n",
        "        predict_name = []\n",
        "        for img, name in test_loader:\n",
        "            if use_gpu:\n",
        "                img = img.to(device)\n",
        "            output = model(img)\n",
        "            predict = torch.argmax(output, dim=-1).tolist()\n",
        "            predict_result += predict\n",
        "            predict_name += name\n",
        "        \n",
        "    with open(file_name, 'w', newline='') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow(['id', 'label'])\n",
        "        for id, r in zip(predict_name, predict_result):\n",
        "            writer.writerow([id, r])\n",
        "\n",
        "    \n",
        "    from google.colab import files\n",
        "    files.download(\"predict.csv\")  \n",
        "\n",
        "test(test_loader, model)\n",
        "torch.save(model.state_dict(), F\"newmodel.pth\" )"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d02bdc0b-9d08-4130-b7f5-def984ffdfa9\", \"predict.csv\", 24010)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqtDLxvkOSz9"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}