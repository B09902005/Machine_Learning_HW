{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OC_P8bFMzILD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.optim import SGD\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "seed = 3047\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "np.random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1o0m3jyfmetUOJ146TqHuEGUWwQyC7JXV\n",
        "!gdown 1B5OC3R0yM8F7yjoYOKu3t08QZalcr7DC\n",
        "!gdown 1THvOuf_EOn6c_6TLy0Bqs23BP2NraBR2"
      ],
      "metadata": {
        "id": "FucrkOKI3m_c",
        "outputId": "f8ac985f-1cee-452c-dbce-d525dee4265e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1o0m3jyfmetUOJ146TqHuEGUWwQyC7JXV\n",
            "To: /content/train.csv\n",
            "100% 6.54M/6.54M [00:00<00:00, 38.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1B5OC3R0yM8F7yjoYOKu3t08QZalcr7DC\n",
            "To: /content/val.csv\n",
            "100% 665k/665k [00:00<00:00, 150MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1THvOuf_EOn6c_6TLy0Bqs23BP2NraBR2\n",
            "To: /content/X_test\n",
            "100% 3.57M/3.57M [00:00<00:00, 260MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SVM(nn.Module):\n",
        "  def __init__(self):\n",
        "    # TODO design your model\n",
        "    super(SVM, self).__init__() \n",
        "    self.w = nn.Parameter(torch.randn((1, 8192)).to(torch.float32))\n",
        "    self.f = nn.Sequential(\n",
        "                  nn.Linear(107, 8192),\n",
        "                  nn.Dropout(0.5),\n",
        "                )\n",
        "  def transform(self, x):\n",
        "    x = self.f(x)\n",
        "    return x\n",
        "  def kernel(self, x):\n",
        "    pass\n",
        "  def forward(self, x):\n",
        "    f = torch.matmul(self.transform(x), self.w.T)\n",
        "    \n",
        "    return f"
      ],
      "metadata": {
        "id": "Iywj8wLF8ppU"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HingeLoss(nn.Module):\n",
        "  def __init__(self, C):\n",
        "    super(HingeLoss, self).__init__()  \n",
        "    self.C = C\n",
        "  def forward(self, y, f):\n",
        "    loss = 0\n",
        "    for i in range(y.shape[0]):\n",
        "      loss = loss + C * max(0, 1-y[i]*f[i])\n",
        "    return loss\n"
      ],
      "metadata": {
        "id": "X2a0522z7IWo"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainDataset(Dataset):\n",
        "  def __init__(self, split, mu=None, std=None):\n",
        "    X = pd.read_csv(f\"{split}.csv\")\n",
        "    \n",
        "    Y = X['y'].values.reshape(-1) * 2 - 1\n",
        "    X['y']\n",
        "    X = self.normalize(X.drop(['y'], axis=1), mu, std)\n",
        "    X = np.concatenate((X, np.ones((X.shape[0], 1))), 1)\n",
        "    self.Y = torch.from_numpy(Y).to(torch.float32)\n",
        "    self.X = torch.from_numpy(X).to(torch.float32)\n",
        "\n",
        "  def normalize(self, X, mu=None, std=None):\n",
        "    for i in ([0,1,3,4,5]):\n",
        "      X.iloc[:,i] = (X.iloc[:,i] - X.iloc[:,i].mean()) / X.iloc[:,i].std()\n",
        "    \n",
        "    return X\n",
        "  \n",
        "  def __len__(self):\n",
        "    return self.X.size(0)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.X[idx], self.Y[idx]\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "  def __init__(self, mu=None, std=None):\n",
        "    X = pd.read_csv(\"X_test\")\n",
        "    X = self.normalize(X, mu, std)\n",
        "    X = np.concatenate((X, np.ones((X.shape[0], 1))), 1)\n",
        "    self.X = torch.from_numpy(X).to(torch.float32)\n",
        "\n",
        "  def normalize(self, X, mu_x, std_x):\n",
        "    for i in ([0,1,3,4,5]):\n",
        "      X.iloc[:,i] = (X.iloc[:,i] - X.iloc[:,i].mean()) / X.iloc[:,i].std()\n",
        "    \n",
        "    return X\n",
        "  \n",
        "  def __len__(self):\n",
        "    return self.X.size(0)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.X[idx]"
      ],
      "metadata": {
        "id": "iBTrbIzE_AI9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_data, val_data, model, optim, C, device='cuda:0'):\n",
        "    epoch = 15\n",
        "    objective = HingeLoss(C)\n",
        "    steps = 0\n",
        "    best = 0\n",
        "    print(epoch * len(train_data))\n",
        "    for e in range(epoch):\n",
        "      for tr in train_data:\n",
        "        steps += 1\n",
        "        x_train, y_train = tr\n",
        "        x_train, y_train = x_train.to(device), y_train.to(device)\n",
        "        pred = model(x_train).squeeze(1)\n",
        "        loss = objective(pred, y_train) + 1 / 2 * torch.sum(model.w[:-1] ** 2)\n",
        "        \n",
        "        optim.zero_grad()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "        \n",
        "        if steps % 100 == 0:\n",
        "          model.eval()\n",
        "          with torch.no_grad():\n",
        "            acc = []\n",
        "            for val in val_data:\n",
        "              x_val, y_val = val\n",
        "              x_val , y_val = x_val.to(device), y_val.to(device)\n",
        "              pred = model(x_val).squeeze(1)\n",
        "              pred = (pred > 0) * 2 - 1\n",
        "              \n",
        "              result = (y_val == pred)\n",
        "              acc += [(float(result.sum()) / result.size(0))]\n",
        "            acc = sum(acc) / len(acc)\n",
        "            print(f'Steps {steps}| Train Loss = {loss.item()}| Val acc = {acc}')\n",
        "            if acc > best:\n",
        "              torch.save(model.state_dict(), 'best.ckpt')\n",
        "              best = acc        \n",
        "          model.train()\n",
        "    return model"
      ],
      "metadata": {
        "id": "m5PZP044Pxuu"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.0001\n",
        "batch = 32\n",
        "C = 1\n",
        "device = 'cuda:0'"
      ],
      "metadata": {
        "id": "ucnbZEiVPia3"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = TrainDataset('train')\n",
        "devset = TrainDataset('val')\n",
        "testset = TestDataset()\n",
        "\n",
        "train_dataloader = DataLoader(trainset, batch, True, drop_last=False)\n",
        "val_dataloader = DataLoader(devset, 1, False)\n",
        "test_dataloader = DataLoader(testset, 1, False)\n",
        "\n",
        "model = SVM().to(device) \n",
        "optim = SGD(model.parameters(), lr)\n",
        "model = train(train_dataloader, val_dataloader, model, optim, C, device)"
      ],
      "metadata": {
        "id": "YF1QyZXG4eI7",
        "outputId": "fa0cb242-de28-4f0e-c7b2-b444e86c25a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13860\n",
            "Steps 100| Train Loss = 159.05892944335938| Val acc = 0.842\n",
            "Steps 200| Train Loss = 122.18543243408203| Val acc = 0.8256666666666667\n",
            "Steps 300| Train Loss = 177.4066925048828| Val acc = 0.8376666666666667\n",
            "Steps 400| Train Loss = 189.41549682617188| Val acc = 0.8383333333333334\n",
            "Steps 500| Train Loss = 164.84390258789062| Val acc = 0.8266666666666667\n",
            "Steps 600| Train Loss = 268.3534851074219| Val acc = 0.794\n",
            "Steps 700| Train Loss = 117.44501495361328| Val acc = 0.8226666666666667\n",
            "Steps 800| Train Loss = 71.41488647460938| Val acc = 0.836\n",
            "Steps 900| Train Loss = 40.548973083496094| Val acc = 0.7996666666666666\n",
            "Steps 1000| Train Loss = 66.96087646484375| Val acc = 0.8336666666666667\n",
            "Steps 1100| Train Loss = 73.95323944091797| Val acc = 0.8343333333333334\n",
            "Steps 1200| Train Loss = 298.15496826171875| Val acc = 0.8156666666666667\n",
            "Steps 1300| Train Loss = 103.84503173828125| Val acc = 0.8036666666666666\n",
            "Steps 1400| Train Loss = 345.66259765625| Val acc = 0.7643333333333333\n",
            "Steps 1500| Train Loss = 218.58401489257812| Val acc = 0.829\n",
            "Steps 1600| Train Loss = 120.32855224609375| Val acc = 0.7743333333333333\n",
            "Steps 1700| Train Loss = 66.82683563232422| Val acc = 0.824\n",
            "Steps 1800| Train Loss = 170.6804962158203| Val acc = 0.8236666666666667\n",
            "Steps 1900| Train Loss = 112.96414184570312| Val acc = 0.8333333333333334\n",
            "Steps 2000| Train Loss = 104.27883911132812| Val acc = 0.8353333333333334\n",
            "Steps 2100| Train Loss = 85.52075958251953| Val acc = 0.7803333333333333\n",
            "Steps 2200| Train Loss = 66.25067138671875| Val acc = 0.8296666666666667\n",
            "Steps 2300| Train Loss = 93.905517578125| Val acc = 0.808\n",
            "Steps 2400| Train Loss = 73.1555404663086| Val acc = 0.8046666666666666\n",
            "Steps 2500| Train Loss = 64.58478546142578| Val acc = 0.7813333333333333\n",
            "Steps 2600| Train Loss = 259.9496765136719| Val acc = 0.7923333333333333\n",
            "Steps 2700| Train Loss = 364.9472961425781| Val acc = 0.792\n",
            "Steps 2800| Train Loss = 139.834716796875| Val acc = 0.83\n",
            "Steps 2900| Train Loss = 195.5352325439453| Val acc = 0.819\n",
            "Steps 3000| Train Loss = 42.275917053222656| Val acc = 0.7883333333333333\n",
            "Steps 3100| Train Loss = 37.588417053222656| Val acc = 0.8463333333333334\n",
            "Steps 3200| Train Loss = 163.63076782226562| Val acc = 0.833\n",
            "Steps 3300| Train Loss = 60.13984298706055| Val acc = 0.7806666666666666\n",
            "Steps 3400| Train Loss = 148.247314453125| Val acc = 0.8293333333333334\n",
            "Steps 3500| Train Loss = 135.9569549560547| Val acc = 0.818\n",
            "Steps 3600| Train Loss = 61.569664001464844| Val acc = 0.8206666666666667\n",
            "Steps 3700| Train Loss = 122.64181518554688| Val acc = 0.8143333333333334\n",
            "Steps 3800| Train Loss = 278.0126647949219| Val acc = 0.713\n",
            "Steps 3900| Train Loss = 292.2070007324219| Val acc = 0.7833333333333333\n",
            "Steps 4000| Train Loss = 73.0368423461914| Val acc = 0.8053333333333333\n",
            "Steps 4100| Train Loss = 52.393638610839844| Val acc = 0.823\n",
            "Steps 4200| Train Loss = 108.65654754638672| Val acc = 0.8283333333333334\n",
            "Steps 4300| Train Loss = 159.82308959960938| Val acc = 0.827\n",
            "Steps 4400| Train Loss = 127.89476776123047| Val acc = 0.8293333333333334\n",
            "Steps 4500| Train Loss = 43.380210876464844| Val acc = 0.8353333333333334\n",
            "Steps 4600| Train Loss = 148.74639892578125| Val acc = 0.8263333333333334\n",
            "Steps 4700| Train Loss = 214.09970092773438| Val acc = 0.8363333333333334\n",
            "Steps 4800| Train Loss = 73.10748291015625| Val acc = 0.8276666666666667\n",
            "Steps 4900| Train Loss = 173.71621704101562| Val acc = 0.824\n",
            "Steps 5000| Train Loss = 194.3135986328125| Val acc = 0.8\n",
            "Steps 5100| Train Loss = 138.37425231933594| Val acc = 0.7916666666666666\n",
            "Steps 5200| Train Loss = 150.57994079589844| Val acc = 0.837\n",
            "Steps 5300| Train Loss = 85.80504608154297| Val acc = 0.809\n",
            "Steps 5400| Train Loss = 205.3509521484375| Val acc = 0.7786666666666666\n",
            "Steps 5500| Train Loss = 90.69070434570312| Val acc = 0.8276666666666667\n",
            "Steps 5600| Train Loss = 116.87049865722656| Val acc = 0.7803333333333333\n",
            "Steps 5700| Train Loss = 149.6904296875| Val acc = 0.8016666666666666\n",
            "Steps 5800| Train Loss = 79.6723403930664| Val acc = 0.8283333333333334\n",
            "Steps 5900| Train Loss = 45.65132141113281| Val acc = 0.7953333333333333\n",
            "Steps 6000| Train Loss = 144.7780303955078| Val acc = 0.8073333333333333\n",
            "Steps 6100| Train Loss = 134.8171844482422| Val acc = 0.811\n",
            "Steps 6200| Train Loss = 130.67625427246094| Val acc = 0.8166666666666667\n",
            "Steps 6300| Train Loss = 138.60528564453125| Val acc = 0.832\n",
            "Steps 6400| Train Loss = 132.74734497070312| Val acc = 0.831\n",
            "Steps 6500| Train Loss = 97.65569305419922| Val acc = 0.8353333333333334\n",
            "Steps 6600| Train Loss = 148.4175567626953| Val acc = 0.7913333333333333\n",
            "Steps 6700| Train Loss = 117.80133819580078| Val acc = 0.824\n",
            "Steps 6800| Train Loss = 225.71896362304688| Val acc = 0.8043333333333333\n",
            "Steps 6900| Train Loss = 56.884002685546875| Val acc = 0.8033333333333333\n",
            "Steps 7000| Train Loss = 36.42414093017578| Val acc = 0.8303333333333334\n",
            "Steps 7100| Train Loss = 122.9277114868164| Val acc = 0.7913333333333333\n",
            "Steps 7200| Train Loss = 180.83055114746094| Val acc = 0.735\n",
            "Steps 7300| Train Loss = 45.57892608642578| Val acc = 0.8113333333333334\n",
            "Steps 7400| Train Loss = 34.15437316894531| Val acc = 0.813\n",
            "Steps 7500| Train Loss = 44.365745544433594| Val acc = 0.7986666666666666\n",
            "Steps 7600| Train Loss = 169.2695770263672| Val acc = 0.8226666666666667\n",
            "Steps 7700| Train Loss = 55.826568603515625| Val acc = 0.832\n",
            "Steps 7800| Train Loss = 120.72735595703125| Val acc = 0.825\n",
            "Steps 7900| Train Loss = 184.88462829589844| Val acc = 0.7833333333333333\n",
            "Steps 8000| Train Loss = 83.10057067871094| Val acc = 0.8366666666666667\n",
            "Steps 8100| Train Loss = 79.90567016601562| Val acc = 0.8046666666666666\n",
            "Steps 8200| Train Loss = 324.0977783203125| Val acc = 0.7856666666666666\n",
            "Steps 8300| Train Loss = 92.69319152832031| Val acc = 0.8326666666666667\n",
            "Steps 8400| Train Loss = 88.00971984863281| Val acc = 0.84\n",
            "Steps 8500| Train Loss = 157.3429718017578| Val acc = 0.828\n",
            "Steps 8600| Train Loss = 64.78517150878906| Val acc = 0.814\n",
            "Steps 8700| Train Loss = 341.11688232421875| Val acc = 0.7713333333333333\n",
            "Steps 8800| Train Loss = 103.52305603027344| Val acc = 0.8253333333333334\n",
            "Steps 8900| Train Loss = 148.12017822265625| Val acc = 0.783\n",
            "Steps 9000| Train Loss = 154.34036254882812| Val acc = 0.7373333333333333\n",
            "Steps 9100| Train Loss = 47.82240295410156| Val acc = 0.8143333333333334\n",
            "Steps 9200| Train Loss = 66.95137023925781| Val acc = 0.844\n",
            "Steps 9300| Train Loss = 141.79180908203125| Val acc = 0.7853333333333333\n",
            "Steps 9400| Train Loss = 56.51410675048828| Val acc = 0.8453333333333334\n",
            "Steps 9500| Train Loss = 187.2397003173828| Val acc = 0.7433333333333333\n",
            "Steps 9600| Train Loss = 65.15504455566406| Val acc = 0.81\n",
            "Steps 9700| Train Loss = 243.22975158691406| Val acc = 0.8126666666666666\n",
            "Steps 9800| Train Loss = 192.4735107421875| Val acc = 0.8286666666666667\n",
            "Steps 9900| Train Loss = 49.582847595214844| Val acc = 0.824\n",
            "Steps 10000| Train Loss = 188.51922607421875| Val acc = 0.7983333333333333\n",
            "Steps 10100| Train Loss = 117.60596466064453| Val acc = 0.8363333333333334\n",
            "Steps 10200| Train Loss = 26.944860458374023| Val acc = 0.836\n",
            "Steps 10300| Train Loss = 73.07868194580078| Val acc = 0.824\n",
            "Steps 10400| Train Loss = 210.41799926757812| Val acc = 0.8273333333333334\n",
            "Steps 10500| Train Loss = 76.07315826416016| Val acc = 0.8276666666666667\n",
            "Steps 10600| Train Loss = 180.5042724609375| Val acc = 0.8316666666666667\n",
            "Steps 10700| Train Loss = 209.89089965820312| Val acc = 0.7853333333333333\n",
            "Steps 10800| Train Loss = 119.66519927978516| Val acc = 0.8213333333333334\n",
            "Steps 10900| Train Loss = 207.2566375732422| Val acc = 0.8223333333333334\n",
            "Steps 11000| Train Loss = 150.25852966308594| Val acc = 0.8103333333333333\n",
            "Steps 11100| Train Loss = 142.72808837890625| Val acc = 0.8373333333333334\n",
            "Steps 11200| Train Loss = 162.5572509765625| Val acc = 0.788\n",
            "Steps 11300| Train Loss = 132.4379119873047| Val acc = 0.816\n",
            "Steps 11400| Train Loss = 264.8749084472656| Val acc = 0.8283333333333334\n",
            "Steps 11500| Train Loss = 100.77747344970703| Val acc = 0.8243333333333334\n",
            "Steps 11600| Train Loss = 192.88819885253906| Val acc = 0.7753333333333333\n",
            "Steps 11700| Train Loss = 236.3578643798828| Val acc = 0.8296666666666667\n",
            "Steps 11800| Train Loss = 117.73081970214844| Val acc = 0.8333333333333334\n",
            "Steps 11900| Train Loss = 78.40802001953125| Val acc = 0.833\n",
            "Steps 12000| Train Loss = 99.37724304199219| Val acc = 0.8383333333333334\n",
            "Steps 12100| Train Loss = 228.08285522460938| Val acc = 0.7983333333333333\n",
            "Steps 12200| Train Loss = 66.03789520263672| Val acc = 0.8346666666666667\n",
            "Steps 12300| Train Loss = 294.58551025390625| Val acc = 0.819\n",
            "Steps 12400| Train Loss = 174.20152282714844| Val acc = 0.8226666666666667\n",
            "Steps 12500| Train Loss = 329.982666015625| Val acc = 0.8386666666666667\n",
            "Steps 12600| Train Loss = 89.8500747680664| Val acc = 0.827\n",
            "Steps 12700| Train Loss = 151.17987060546875| Val acc = 0.831\n",
            "Steps 12800| Train Loss = 121.87916564941406| Val acc = 0.8353333333333334\n",
            "Steps 12900| Train Loss = 227.70205688476562| Val acc = 0.8023333333333333\n",
            "Steps 13000| Train Loss = 93.42119598388672| Val acc = 0.8213333333333334\n",
            "Steps 13100| Train Loss = 74.10935974121094| Val acc = 0.815\n",
            "Steps 13200| Train Loss = 47.69825744628906| Val acc = 0.8303333333333334\n",
            "Steps 13300| Train Loss = 53.07118225097656| Val acc = 0.8266666666666667\n",
            "Steps 13400| Train Loss = 139.378173828125| Val acc = 0.8403333333333334\n",
            "Steps 13500| Train Loss = 180.54269409179688| Val acc = 0.802\n",
            "Steps 13600| Train Loss = 84.99819946289062| Val acc = 0.825\n",
            "Steps 13700| Train Loss = 136.29620361328125| Val acc = 0.8\n",
            "Steps 13800| Train Loss = 65.53958129882812| Val acc = 0.8326666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = model\n",
        "best_model.load_state_dict(torch.load('best.ckpt'))\n",
        "best_model = best_model.eval()\n",
        "\n",
        "y_test = []\n",
        "for x in test_dataloader:\n",
        "  x = x.to(device)\n",
        "  y = best_model(x)\n",
        "  y_test.append(((y > 0) * 1).item())\n",
        "\n"
      ],
      "metadata": {
        "id": "42J0DE2DQQ8u"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "with open('predict.csv', 'w', newline='') as csvf:\n",
        "    # 建立 CSV 檔寫入器\n",
        "    writer = csv.writer(csvf)\n",
        "    writer.writerow(['id','label'])\n",
        "    for i in range(len(y_test)):\n",
        "      writer.writerow( [i + 1, int(y_test[i])] )"
      ],
      "metadata": {
        "id": "sYJnjxOiQKqB"
      },
      "execution_count": 86,
      "outputs": []
    }
  ]
}